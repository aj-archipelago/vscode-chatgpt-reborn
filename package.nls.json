{
  "apiKeySetup.heading": "OpenAI API Key Setup",
  "apiKeySetup.instructions.toUseExtension": "To use this extension, you must have an OpenAI API key. You can follow the instructions below to get one.",
  "apiKeySetup.instructions.title": "Instructions:",
  "apiKeySetup.instructions.step1": "Create an OpenAI account if you haven't at",
  "apiKeySetup.instructions.step2": "Then, go to",
  "apiKeySetup.instructions.step3": "Click \"Create API Key\"",
  "apiKeySetup.instructions.step4": "Copy the key and paste it in the text input below to set it up.",
  "apiKeySetup.instructions.step5a": "On submit the key is securely stored on your computer using VSCode secret storage. It is never sent to any server. (This extension is open source, so",
  "apiKeySetup.instructions.step5b": "you can even check for yourself",
  "apiKeySetup.instructions.step5c": "!)",
  "apiKeySetup.apiKeyLabel": "API Key",
  "apiKeySetup.settingApiKey": "Setting API Key...",
  "apiKeySetup.setApiKey": "Set API Key",
  "apiKeySetup.invalidApiKey.title": "Invalid API Key",
  "apiKeySetup.invalidApiKey.description": "The API key you entered has failed to get an OK response from OpenAI. Please double check the key was copied in correctly. Also, check that OpenAI is not currently experiencing an API outage. (",
  "apiKeySetup.invalidApiKey.closingParenthesis": ")",
  "apiKeySetup.openAIAPICosts.title": "Note: OpenAI API has costs associated with it",
  "apiKeySetup.openAIAPICosts.description": "If you're not already aware - OpenAI's API does have costs associated with it. However, new accounts do receive a $5 credit to get started. When you ask a question in this extension, it will likely cost a fraction of a cent in API usage.",
  "apiKeySetup.openAIAPICosts.examplePart1": "For example if all of the text in this extension window was from ai, it would've cost",
  "apiKeySetup.openAIAPICosts.examplePart2": "in API usage on GPT-3.5-turbo. Beware if you use OpenAI's latest model, GPT-4, it is",
  "apiKeySetup.openAIAPICosts.examplePart3": "more expensive than GPT-3.5-turbo at",
  "apiKeySetup.openAIAPICosts.moreDetails": "View openai.com/pricing for more details",
  "chat.send": "Send",
  "chat.cancel": "Cancel",
  "chat.you": "You",
  "chat.ai": "Knuth",
  "knuth-vsc.freeText.title": "Knuth: Ask anything",
  "knuth-vsc.clearSession.title": "Knuth: Reset session",
  "knuth-vsc.generateCode.title": "Knuth-Codex: Generate code",
  "knuth-vsc.addTests.title": "Knuth: Add tests",
  "knuth-vsc.findProblems.title": "Knuth: Find bugs",
  "knuth-vsc.optimize.title": "Knuth: Optimize",
  "knuth-vsc.explain.title": "Knuth: Explain",
  "knuth-vsc.addComments.title": "Knuth: Add comments",
  "knuth-vsc.completeCode.title": "Knuth: Complete code",
  "knuth-vsc.adhoc.title": "Knuth: Ad-hoc prompt",
  "knuth-vsc.customPrompt1.title": "Knuth: Custom prompt 1",
  "knuth-vsc.customPrompt2.title": "Knuth: Custom prompt 2",
  "knuth-vsc.clearConversation.title": "Knuth: Clear conversation",
  "knuth-vsc.exportConversation.title": "Knuth: Export conversation",
  "knuth-vsc-view-container.name": "Conversation window",
  "knuth-vsc.gpt3.generateCode-enabled.description": "Enable the code generation context menu item for the selected comment/code for Codex. Only available with code-* models",
  "knuth-vsc.promptPrefix.addTests.default": "Implement tests for the following code",
  "knuth-vsc.promptPrefix.addTests.description": "The prompt prefix used for adding tests for the selected code",
  "knuth-vsc.promptPrefix.addTests-enabled.description": "Enable the prompt prefix used for adding tests for the selected code in the context menu",
  "knuth-vsc.promptPrefix.findProblems.default": "Find problems with the following code",
  "knuth-vsc.promptPrefix.findProblems.description": "The prompt prefix used for finding problems for the selected code",
  "knuth-vsc.promptPrefix.findProblems-enabled.description": "Enable the prompt prefix used for finding problems for the selected code in the context menu",
  "knuth-vsc.promptPrefix.optimize.default": "Optimize the following code",
  "knuth-vsc.promptPrefix.optimize.description": "The prompt prefix used for optimizing the selected code",
  "knuth-vsc.promptPrefix.optimize-enabled.description": "Enable the prompt prefix used for optimizing the selected code in the context menu",
  "knuth-vsc.promptPrefix.explain.default": "Explain the following code",
  "knuth-vsc.promptPrefix.explain.description": "The prompt prefix used for explaining the selected code",
  "knuth-vsc.promptPrefix.explain-enabled.description": "Enable the prompt prefix used for explaining the selected code in the context menu",
  "knuth-vsc.promptPrefix.addComments.default": "Add comments for the following code",
  "knuth-vsc.promptPrefix.addComments.description": "The prompt prefix used for adding comments for the selected code",
  "knuth-vsc.promptPrefix.addComments-enabled.description": "Enable the prompt prefix used for adding comments for the selected code in the context menu",
  "knuth-vsc.promptPrefix.completeCode.default": "Complete the following code",
  "knuth-vsc.promptPrefix.completeCode.description": "The prompt prefix used for completing the selected code",
  "knuth-vsc.promptPrefix.completeCode-enabled.description": "Enable the prompt prefix used for completing the selected code in the context menu",
  "knuth-vsc.promptPrefix.customPrompt1.description": "Your custom prompt. It's disabled by default, please set to a custom prompt and enable it if you prefer using customized prompt",
  "knuth-vsc.promptPrefix.customPrompt1-enabled.markdownDescription": "Enable the prompt prefix used for your custom prompt. The default value is empty, if you enable this item make sure to set this `knuth-vsc.promptPrefix.customPrompt1`",
  "knuth-vsc.promptPrefix.customPrompt2.description": "Your custom prompt. It's disabled by default, please set to a custom prompt and enable it if you prefer using customized prompt",
  "knuth-vsc.promptPrefix.customPrompt2-enabled.markdownDescription": "Enable the prompt prefix used for your custom prompt. The default value is empty, if you enable this item make sure to set this `knuth-vsc.promptPrefix.customPrompt2`",
  "knuth-vsc.promptPrefix.adhoc-enabled.description": "Enable the prompt prefix used for adhoc command for the selected code in the context menu",
  "knuth-vsc.gpt3.apiKey.markdownDescription": "OpenAI API key. [Get your API Key from OpenAI](https://beta.openai.com/account/api-keys).",
  "knuth-vsc.gpt3.apiBaseUrl.markdownDescription": "Optional override for the OpenAI API base URL. If you customize it, please make sure you have the same format. e.g. starts with `https://` without a trailing slash. The completions endpoint suffix is added internally, e.g. for reference: `${apiBaseUrl}/v1/completions`",
  "knuth-vsc.gpt3.organization.markdownDescription": "OpenAI Organization ID. [Documentation](https://beta.openai.com/docs/api-reference/requesting-organization).",
  "knuth-vsc.gpt3.model.markdownDescription": "OpenAI models to use for your prompts. [Documentation](https://beta.openai.com/docs/models/models). \n\n**If you face 400 Bad Request please make sure you are using the right model for your integration method.**",
  "knuth-vsc.gpt3.model.enumItemLabels1": "OpenAI API Key - gpt-4",
  "knuth-vsc.gpt3.model.enumItemLabels2": "OpenAI API Key - gpt-3.5-turbo",
  "knuth-vsc.gpt3.model.enumItemLabels3": "OpenAI API Key - gpt-3.5-turbo-16k",
  "knuth-vsc.gpt3.model.enumItemLabels4": "OpenAI API Key - text-davinci-003",
  "knuth-vsc.gpt3.model.enumItemLabels5": "OpenAI API Key - text-curie-001",
  "knuth-vsc.gpt3.model.enumItemLabels6": "OpenAI API Key - text-babbage-001",
  "knuth-vsc.gpt3.model.enumItemLabels7": "OpenAI API Key - text-ada-001",
  "knuth-vsc.gpt3.model.enumItemLabels8": "OpenAI API Key - code-davinci-002",
  "knuth-vsc.gpt3.model.enumItemLabels9": "OpenAI API Key - code-cushman-001",
  "knuth-vsc.gpt3.model.markdownEnumDescriptions1": "GPT-4",
  "knuth-vsc.gpt3.model.markdownEnumDescriptions2": "Most capable GPT-3.5 model and optimized for chat at 1/10th the cost of `text-davinci-003`. Will be updated with our latest model iteration.",
  "knuth-vsc.gpt3.model.markdownEnumDescriptions3": "Snapshot of `gpt-3.5-turbo` from March 1st 2023. Unlike gpt-3.5-turbo, this model will not receive updates, and will only be supported for a three month period ending on June 1st 2023.",
  "knuth-vsc.gpt3.maxTokens.markdownDescription": "The maximum number of tokens to generate in the completion. \n\nThe token count of your prompt plus max_tokens cannot exceed the model's context length. Most models have a context length of 2048 tokens (except for the newest models, which support 4096). [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-max_tokens)",
  "knuth-vsc.gpt3.temperature.markdownDescription": "What sampling temperature to use. Higher values means the model will take more risks. Try 0.9 for more creative applications, and 0 (argmax sampling) for ones with a well-defined answer.\n\nIt is recommended altering this or top_p but not both. [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-temperature)",
  "knuth-vsc.gpt3.top_p.markdownDescription": "An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered. \n\nIt is recommended altering this or temperature but not both. [Documentation](https://beta.openai.com/docs/api-reference/completions/create#completions/create-top_p)",
  "knuth-vsc.response.showNotification.description": "Choose whether you'd like to receive a notification when Knuth bot responds to your query.",
  "knuth-vsc.response.autoScroll.description": "Whenever there is a new question or response added to the conversation window, extension will automatically scroll to the bottom. You can change that behavior by disabling this setting.",
  "codeBlock.expand": "Expand",
  "codeBlock.collapse": "Collapse",
  "codeBlock.copy": "Copy",
  "codeBlock.copied": "Copied",
  "codeBlock.copyTooltip": "Copy to clipboard",
  "codeBlock.insertTooltip": "Insert into the current file",
  "codeBlock.insert": "Insert",
  "codeBlock.inserted": "Inserted",
  "codeBlock.newTooltip": "Create a new file with the below code",
  "codeBlock.new": "New",
  "codeBlock.created": "Created",
  "customPromptPanel.closeButton": "Close",
  "customPromptPanel.newPrompt": "New",
  "customPromptPanel.newFromTemplate": "New from template",
  "introSplash.features.title": "Features",
  "introductionSplash.features.feature1": "Optimize, refactor, and debug your code",
  "introductionSplash.features.feature2": "Create tests, READMEs, and more",
  "introductionSplash.features.feature3": "Automatic syntax highlighting",
  "introductionSplash.features.feature4": "Run multiple chats at once",
  "introSplash.discontinued1": "This is an API-only fork of ",
  "introductionSplash.discontinued": "discontinued",
  "introductionSplash.discontinued2": "Knuth-Vsc extension.",
  "options.title": "Options",
  "questionInputField.stop": "Stop",
  "questionInputField.tokens": "tokens",
  "questionInputField.thinking": "Thinking...",
  "questionInputField.ask": "Ask",
  "questionInputField.useEditorSelection": "Editor selection",
  "questionInputField.clear": "Clear",
  "questionInputField.feedback": "Feedback",
  "questionInputField.debug": "Debug",
  "questionInputField.settings": "Settings",
  "questionInputField.exportJson": "JSON",
  "questionInputField.resetAPIKey": "Reset API Key",
  "questionInputField.tokenBreakdownHeading": "Pressing Ask will cost...",
  "questionInputField.tokenBreakdownPricing": "pricing",
  "questionInputField.tokenBreakdownForPromptsAndCompletions": "for prompts and completions.",
  "questionInputField.tokenBreakdownRecommendation": "Strongly recommended - clear the conversation routinely to keep the prompt short.",
  "questionInputField.moreActions": "More Actions",
  "questionInputField.tokenBreakdownAtLeast": "At least:",
  "questionInputField.tokenBreakdownAtLeastNote": "(all messages + prompt)",
  "questionInputField.tokenBreakdownTokensWhichIs": "tokens which is",
  "questionInputField.tokenBreakdownAtMost": "At most:",
  "questionInputField.tokenBreakdownAtMostNote": "(all messages + prompt + longest answer)",
  "questionInputField.tokenBreakdownBasedOn": "This is calculated based on the",
  "questionInputField.maxTokens": "maxTokens",
  "questionInputField.tokenBreakdownConfigSettingAnd": "This is calculated based on the",
  "modelSelect.chat": "Chat",
  "modelSelect.gpt35TurboNote": "(Fast, recommended)",
  "modelSelect.gpt35Turbo16kNote": "(Fast, 4x longer input)",
  "modelSelect.gpt4Note": "(Better and larger input, but slower and more pricey)",
  "modelSelect.gpt4UnavailableNote": "Looking for GPT-4? You need to sign up on the waitlist here",
  "modelSelect.gpt432kNote": "Extremely long input, but even more pricey than GPT-4",
  "modelSelect.gpt432kUnavailableNote": "OpenAI has not yet released GPT-4 32k.",
  "stats.title": "Stats",
  "tabs.sr_label": "Select a tab",
  "tabs.sr_close_tab": "Close tab",
  "tabs.new_chat": "New Chat",
  "verbosity.codeLabel": "Code",
  "verbosity.conciseLabel": "Concise",
  "verbosity.normalLabel": "Normal",
  "verbosity.fullLabel": "Detailed",
  "verbosity.codeDescription": "Only reply with code",
  "verbosity.conciseDescription": "Concise explanations",
  "verbosity.normalDescription": "Normal explanations",
  "verbosity.fullDescription": "Detailed, full explanations",
  "verbosity.parentTooltip": "Change the verbosity of the AI's responses"
}